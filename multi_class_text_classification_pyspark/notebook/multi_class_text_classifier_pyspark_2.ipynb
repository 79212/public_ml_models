{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.100:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>multi_class_text_classifiter</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11eb55e90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "MAX_MEMORY = \"5g\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName('multi_class_text_classifiter')\\\n",
    "                    .config(\"spark.executor.memory\", MAX_MEMORY) \\\n",
    "                    .config(\"spark.driver.memory\", MAX_MEMORY) \\\n",
    "                    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"value\", StringType(), True)\n",
    "])\n",
    "total_df = spark.createDataFrame([], schema)\n",
    "\n",
    "for file_name in os.listdir(\"../data\"):\n",
    "    df = spark.read.option(\"header\", \"true\").text('../data/' + file_name)\n",
    "    total_df = total_df.union(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3297"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|    ### abstract ###|\n",
      "|AIMX\twe test in t...|\n",
      "|OWNX\twe manipulat...|\n",
      "|OWNX\tour analysis...|\n",
      "|OWNX\tthe magnitud...|\n",
      "|OWNX\twe conclude ...|\n",
      "|### introduction ###|\n",
      "|MISC\tlured by tem...|\n",
      "|MISC\tself-control...|\n",
      "|MISC\tfor example,...|\n",
      "|MISC\tthe student ...|\n",
      "|MISC\tand, similar...|\n",
      "|MISC\tperhaps less...|\n",
      "|MISC\tthis concept...|\n",
      "|MISC\tthat individ...|\n",
      "|MISC\tfor example,...|\n",
      "|MISC\tnonetheless,...|\n",
      "|MISC\tthat is, pro...|\n",
      "|MISC\tself-control...|\n",
      "|MISC\ta multitude ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_line(x):\n",
    "    line = x['value']\n",
    "    parts = re.split(\"\\s+\",line,1)\n",
    "    sub_parts = re.split('--', parts[0])\n",
    "    parts_1 = ''\n",
    "    if len(sub_parts) > 1:\n",
    "       parts_1 = sub_parts[1] + ' ' + parts[1]\n",
    "    else:\n",
    "       parts_1 = parts[1]\n",
    "    return ([sub_parts[0],parts_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|  _1|                  _2|\n",
      "+----+--------------------+\n",
      "|AIMX|we test in the co...|\n",
      "|OWNX|we manipulated th...|\n",
      "|OWNX|our analysis reve...|\n",
      "|OWNX|the magnitude of ...|\n",
      "|OWNX|we conclude that ...|\n",
      "|MISC|lured by temptati...|\n",
      "|MISC|self-control fail...|\n",
      "|MISC|for example, the ...|\n",
      "|MISC|the student may f...|\n",
      "|MISC|and, similarly, t...|\n",
      "|MISC|perhaps less intu...|\n",
      "|MISC|this conceptualiz...|\n",
      "|MISC|that individuals ...|\n",
      "|MISC|for example, many...|\n",
      "|MISC|nonetheless, one ...|\n",
      "|MISC|that is, pro-soci...|\n",
      "|MISC|self-control-our ...|\n",
      "|MISC|a multitude of co...|\n",
      "|MISC|typically, and in...|\n",
      "|MISC|willpower, then, ...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_rdd = total_df.rdd \\\n",
    "                    .filter(lambda x : x['value'] not in ['### introduction ###','### abstract ###']) \\\n",
    "                    .map(lambda x : process_line(x))\n",
    "\n",
    "input_df = input_rdd.toDF()\n",
    "input_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|  _1|count|\n",
      "+----+-----+\n",
      "|BASE|   61|\n",
      "|OWNX|  867|\n",
      "|CONT|  170|\n",
      "|MISC| 1825|\n",
      "|AIMX|  194|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_df.groupBy('_1').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.parsing.preprocessing as gsp\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from gensim import utils\n",
    "\n",
    "\n",
    "filters = [\n",
    "           gsp.strip_tags, \n",
    "           gsp.strip_punctuation,\n",
    "           gsp.strip_multiple_whitespaces,\n",
    "           gsp.strip_numeric,\n",
    "           gsp.remove_stopwords, \n",
    "           gsp.strip_short, \n",
    "           gsp.stem_text\n",
    "          ]\n",
    "\n",
    "def clean_text(x):\n",
    "    s = x[1]\n",
    "    s = s.lower()\n",
    "    s = utils.to_unicode(s)\n",
    "    for f in filters:\n",
    "        s = f(s)\n",
    "    return (x[0],s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'we test in the context of a dictator game the proposition that individuals may experience a self-control conflict between the temptation to act selfishly and the better judgment to act pro-socially'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_rdd.take(1)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'test context dictat game proposit individu experi self control conflict temptat act selfishli better judgment act pro social'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(input_rdd.take(1)[0])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_rdd = input_rdd.map(lambda x : clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|  _1|                  _2|\n",
      "+----+--------------------+\n",
      "|AIMX|test context dict...|\n",
      "|OWNX|manipul likelihoo...|\n",
      "|OWNX|analysi reveal po...|\n",
      "|OWNX|magnitud effect e...|\n",
      "|OWNX|conclud subtl cue...|\n",
      "|MISC|lure temptat indi...|\n",
      "|MISC|self control fail...|\n",
      "|MISC|exampl dieter fac...|\n",
      "|MISC|student feel conf...|\n",
      "|MISC|similarli fashion...|\n",
      "|MISC|intuit importantl...|\n",
      "|MISC|conceptu help rec...|\n",
      "|MISC|individu care sel...|\n",
      "|MISC|exampl individu v...|\n",
      "|MISC|nonetheless imagi...|\n",
      "|MISC|pro social prefer...|\n",
      "|MISC|self control capa...|\n",
      "|MISC|multitud conceptu...|\n",
      "|MISC|typic line classi...|\n",
      "|MISC|willpow repres co...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = cleaned_rdd.toDF()\n",
    "cleaned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"_2\", outputCol=\"tokens\")\n",
    "w2v = Word2Vec(vectorSize=300, minCount=0, inputCol=\"tokens\", outputCol=\"features\")\n",
    "doc2vec_pipeline = Pipeline(stages=[tokenizer,w2v])\n",
    "doc2vec_model = doc2vec_pipeline.fit(cleaned_df)\n",
    "doc2vecs_df = doc2vec_model.transform(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+--------------------+\n",
      "|  _1|                  _2|              tokens|            features|\n",
      "+----+--------------------+--------------------+--------------------+\n",
      "|AIMX|test context dict...|[test, context, d...|[-0.0369722979828...|\n",
      "|OWNX|manipul likelihoo...|[manipul, likelih...|[-0.0605062282910...|\n",
      "|OWNX|analysi reveal po...|[analysi, reveal,...|[-0.0351625842740...|\n",
      "|OWNX|magnitud effect e...|[magnitud, effect...|[0.00155935803195...|\n",
      "|OWNX|conclud subtl cue...|[conclud, subtl, ...|[-0.0070894029567...|\n",
      "|MISC|lure temptat indi...|[lure, temptat, i...|[-0.0176912855919...|\n",
      "|MISC|self control fail...|[self, control, f...|[-0.0023453514066...|\n",
      "|MISC|exampl dieter fac...|[exampl, dieter, ...|[-0.0113371225265...|\n",
      "|MISC|student feel conf...|[student, feel, c...|[-0.0150255131185...|\n",
      "|MISC|similarli fashion...|[similarli, fashi...|[-0.0130583480304...|\n",
      "|MISC|intuit importantl...|[intuit, importan...|[-0.0272456038722...|\n",
      "|MISC|conceptu help rec...|[conceptu, help, ...|[-0.0431411632802...|\n",
      "|MISC|individu care sel...|[individu, care, ...|[-9.4883576301591...|\n",
      "|MISC|exampl individu v...|[exampl, individu...|[0.00670604280506...|\n",
      "|MISC|nonetheless imagi...|[nonetheless, ima...|[-0.0088679128520...|\n",
      "|MISC|pro social prefer...|[pro, social, pre...|[-0.0399366590839...|\n",
      "|MISC|self control capa...|[self, control, c...|[-0.0392140684250...|\n",
      "|MISC|multitud conceptu...|[multitud, concep...|[0.00367905072926...|\n",
      "|MISC|typic line classi...|[typic, line, cla...|[-0.0207802646125...|\n",
      "|MISC|willpow repres co...|[willpow, repres,...|[0.02033606670139...|\n",
      "+----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc2vecs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_train_df, w2v_test_df = doc2vecs_df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "si = StringIndexer(inputCol=\"_1\", outputCol=\"label\")\n",
    "rf_classifier = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "rf_classifier_pipeline = Pipeline(stages=[si,rf_classifier])\n",
    "rf_predictions = rf_classifier_pipeline.fit(w2v_train_df).transform(w2v_test_df)\n",
    "\n",
    "rf_model_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.641141\n"
     ]
    }
   ],
   "source": [
    "accuracy = rf_model_evaluator.evaluate(rf_predictions)\n",
    "print(\"Accuracy = %g\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr_classifier = LogisticRegression(family=\"multinomial\")\n",
    "\n",
    "lr_classifier_pipeline = Pipeline(stages=[si,lr_classifier])\n",
    "lr_predictions = lr_classifier_pipeline.fit(w2v_train_df).transform(w2v_test_df)\n",
    "\n",
    "lr_model_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.624625\n"
     ]
    }
   ],
   "source": [
    "accuracy = lr_model_evaluator.evaluate(lr_predictions)\n",
    "print(\"Accuracy = %g\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
